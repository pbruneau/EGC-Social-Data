{
  "messages": [
    {
      "message": "Atelier Visualisation, Interaction et Fouille de données à #EGC2018, deadline pour résumés le 1/12  https://t.co/BEfpB88WCy",
      "created_time": "2017-11-12T19:35:22+0000"
    },
    {
      "message": "Atelier Fouille de Données Complexes à #EGC2018 Deadline le 29/11, plus d’infos à https://t.co/EK93nks6Uy",
      "created_time": "2017-11-09T09:27:19+0000"
    },
    {
      "message": "Atelier TextMine #EGC2018 Fouille de texte, deadline le 1/12 https://t.co/5FwHTEYfGx",
      "created_time": "2017-11-05T16:22:35+0000"
    },
    {
      "likes": [
        {
          "id": "10204781517191830",
          "name": "Rim Moussa"
        }
      ],
      "message": "Atelier GAST (Gestion et Analyse des données Spatiales et Temporelles) #EGC2018, deadline le 1/12 https://t.co/FhjfB58JKJ",
      "created_time": "2017-11-05T16:19:53+0000"
    },
    {
      "message": "#EGC2018 appel à démonstrations à https://lnkd.in/guJEQuV\nDeadline le 4/11, prix de 500€ à la clé !",
      "created_time": "2017-10-26T16:44:57+0000"
    },
    {
      "message": "Pré-inscriptions ouvertes pour la 4ème Ecole d'hiver é-EGC \"Réseaux Sociaux\" (https://egc18.sciencesconf.org/resource/page/id/21) en conj. avec la Conférence #EGC2018 !",
      "created_time": "2017-10-26T16:44:01+0000"
    },
    {
      "message": "Deadline pour résumés d'articles courts et longs #EGC2018 étendue jusqu'au mardi 10/10 ! https://egc18.sciencesconf.org/resource/page/id/10",
      "created_time": "2017-10-07T06:58:11+0000"
    },
    {
      "message": "Deadline pour les soumissions d'ateliers #EGC2018 #Paris le 6/10 !",
      "created_time": "2017-10-02T20:00:17+0000"
    },
    {
      "likes": [
        {
          "id": "10153500769602118",
          "name": "Cyril de Runz"
        }
      ],
      "message": "Deadline pour les abstracts de contributions #EGC2018 #Paris le 6/10 ! Idem pour les contributions #Defi ! https://egc18.sciencesconf.org/resource/page/id/10",
      "created_time": "2017-10-02T19:59:47+0000"
    },
    {
      "likes": [
        {
          "id": "10204781517191830",
          "name": "Rim Moussa"
        }
      ],
      "message": "Le prix de thèse de l'édition #EGC2018 est doté de 500€. Modalités à http://bit.ly/2f9OjW5 , deadline le 13/10/2017",
      "created_time": "2017-09-10T15:03:40+0000"
    },
    {
      "message": "Deadline pour soumission des ateliers #EGC2018 #Paris le 6/10/2017 ! http://bit.ly/2pu1mVv",
      "created_time": "2017-09-10T15:03:06+0000"
    },
    {
      "message": "Défi #EGC2018 #Paris sur données météo ! Détails à http://bit.ly/2mclSvA  et modalités à http://bit.ly/2pfl8YE , deadline le 6/10/2017",
      "created_time": "2017-09-09T11:22:53+0000"
    },
    {
      "likes": [
        {
          "id": "10204781517191830",
          "name": "Rim Moussa"
        }
      ],
      "message": "Deadline pour soumissions à #EGC2018 #Paris le 6/10/2017 ! http://bit.ly/2pfl8YE  A vos papiers !",
      "created_time": "2017-09-09T11:22:21+0000"
    },
    {
      "message": "Appel à propositions d'ateliers #EGC2018 #Paris",
      "created_time": "2017-06-30T08:25:38+0000"
    },
    {
      "message": "Appel à communications #EGC2018 #Paris",
      "created_time": "2017-06-30T08:24:51+0000"
    },
    {
      "likes": [
        {
          "id": "617194565039337",
          "name": "Yarabi Ljanna"
        }
      ],
      "message": "Programmes des journées #BDMV - Regards Croisés sur les Data les 26-27/06 à Lille",
      "created_time": "2017-06-19T13:29:39+0000"
    },
    {
      "message": "Appel à participation aux journées #BDMV - Regards Croisés sur les Data, les 26/27/06 à Lille",
      "created_time": "2017-06-19T13:28:04+0000"
    },
    {
      "message": "Appel à démonstrations #EGC2018 #Paris avec un prix de 500€ !",
      "created_time": "2017-05-11T11:05:32+0000"
    },
    {
      "likes": [
        {
          "id": "10201032777737122",
          "name": "Mouhamadou Toure"
        }
      ],
      "message": "Défi #EGC2018 sur la prédiction et l'exploration de données météo !",
      "created_time": "2017-05-09T08:28:28+0000"
    },
    {
      "message": "Appel à propositions d'ateliers #EGC2018 #Paris !",
      "created_time": "2017-05-09T08:27:54+0000"
    },
    {
      "message": "1er appel à communications #EGC2018 #Paris ! bit.ly/2pfl8YE",
      "created_time": "2017-05-09T08:27:20+0000"
    },
    {
      "likes": [
        {
          "id": "617194565039337",
          "name": "Yarabi Ljanna"
        },
        {
          "id": "10155209677725034",
          "name": "Meriem Zekri"
        }
      ],
      "message": "Appel à communications aux journées GT EGC-AFIHM les 26-27/06 - Regards croisés sur les data",
      "created_time": "2017-05-09T08:26:25+0000"
    },
    {
      "comments": [
        {
          "id": "1554755874813762",
          "name": "Association EGC - Extraction et Gestion des Connaissances",
          "message": "Il n'y a pas eu d'action équivalente à EGC 2016, à ma connaissance.",
          "created_time": "2017-04-21T05:54:07+0000"
        },
        {
          "id": "635227039910639",
          "name": "Cyrine Chalghouf",
          "message": "ou peut on trouvé celles de EGC2016?",
          "created_time": "2017-04-20T10:10:27+0000"
        }
      ],
      "message": "Les photos d'EGC 2017 à Grenoble : https://t.co/TEsial1iQw Merci Jean-Philippe Guilbaud !",
      "created_time": "2017-02-11T15:19:33+0000"
    },
    {
      "likes": [
        {
          "id": "617194565039337",
          "name": "Yarabi Ljanna"
        },
        {
          "id": "10153500769602118",
          "name": "Cyril de Runz"
        }
      ],
      "message": "Suivez la conférence EGC 2017 sur Twitter : https://twitter.com/associationEGC",
      "created_time": "2017-01-25T11:24:11+0000"
    },
    {
      "message": "Analyse et fouille de données pour le véhicule autonome @ EGC 2017 \n\nGrenoble   23 Janvier 2017\n\nContexte\n\nLe véhicule à conduite déléguée prend de plus en plus d'ampleur, la majorité des nouveaux véhicules sur le marché sont équipés de capteurs et sont capables d'effectuer des tâches simples comme détecter un obstacle ou réguler leur vitesse en fonction des objets présents dans la scène. La détection d'obstacles fait appel à des techniques de traitement de données hétérogènes afin de comprendre une scène et l'interpréter. Dans la majorité des cas, l'utilisation de techniques de clustering est efficace et permet de détecter les obstacles et les objets de la route (marquage au sol, passage piétons, panneaux, feux tricolore, etc.). Celles-ci peuvent cependant être renforcées par l'utilisation de techniques d'apprentissage supervisé, qui viennent annoter et labelliser les objets de la scène. Plusieurs équipes de recherche, académique ou industrielle, travaillent sur ces sujets pour rendre complètement autonome un véhicule. Les équipes de recherche de Google et de Uber par exemple, utilisent des techniques d'apprentissage pour enrichir la connaissance du véhicule, lui permettre de se conduire lui-même, comprendre son environnement et s'adapter aux situations de conduite. Il y a donc, une émergence des algorithmes, des capteurs et des calculateurs dans le véhicule qui embarquent à bord des techniques d'analyse et de fouille de données.\nObjectifs\n\nL'objectif de cet atelier est de faire se rencontrer des acteurs de la recherche académique et industrielle afin de débattre sur des techniques d'extraction et de gestion de la connaissance appliquées à des données capteurs (Image, LIDAR, RADAR) qui peuvent être utilisées dans des véhicules à conduite déléguée.\n\n \n\nThématiques\n\nApprentissage non-supervisé,\nApprentissage supervisé,\nTraitement d'image,\nTraitement de points 3D,\nStructuration de points 3D,\nReconstruction de surface à partir de points 3D,\nCalibration et autocalibration de capteurs,\nFusion de données multicapteurs,\nSuivi d'objets 3D,\nPlanification et contrôle commande.\n\nDates importantes\n\nRéception des résumés (1/2 page)\n7  novembre 2016\nNotification d'acceptation des résumés\n10 novembre 2016\nRéception des papiers\n20 novembre 2016\nNotification aux auteurs\n15 décembre 2016\nDate de l'atelier\n23 Janvier 2017\nProcédure de soumission\n\nPour soumettre, merci d'utiliser le lien ci-dessous en choisissant l'atelier AFDAV dans les options:\nhttps://easychair.org/conferences/?conf=egc2017.\nToutes les soumissions doivent contenir au minimum six (6) pages et au plus douze (12) pages et être soumises au format pdf exclusivement. Elles devront impérativement utiliser le format RNTI latex :\nhttp://www.editions-rnti.fr/files/RNTI-X-Y2.1.zip.\nComités\n\nOrganisation\n\nMohamed-Cherif Rahal, VEDECOM - Versailles (mohamed.rahal@vedecom.fr)\nSebastien Glaser, VEDECOM - Versailles (sebastien.glaser@vedecom.fr)\nGuillaume Bresson, VEDECOM - Versailles (guillaume.bresson@vedecom.fr)",
      "created_time": "2016-11-03T23:41:21+0000"
    },
    {
      "message": "En conjonction avec le congrès EGC, Grenoble, 24 janvier 2017\n\nhttp://CompJournalism2017.irisa.fr\n\nDates importantes\n-----------------\n    Date limite de soumission des articles : 27/11/2016\n    Notification aux auteurs : 19/12/2016\n    Version finale : 08/01/2017\n    Atelier : 24/01/2017\n\nAppel à contributions\n---------------------\nDepuis quelques années, journalistes et technologues ont développé la notion de “journalisme de données''. Cette pratique nouvelle du journalisme tire partie des données numériques disponibles pour produire et distribuer l'information. Elle bénéficie notamment de la popularité croissante de l'Open Data, du développement de bases de connaissances structurées, du traitement automatique des langues, ainsi que des travaux récents en visualisation de données, pour faciliter l'analyse de l'information et proposer une grande variété de points de vue.\nL'objectif principal de l'atelier est de servir de lieu de rencontre entre les différents acteurs de cette communauté. Ceux-ci relèvent souvent de sous-domaines de l'informatique différentes (RI, TAL, BD, web sémantique, visualisation…) se rencontrant assez peu, alors que les problématiques impliquent une démarche intégrant tous ces sous-domaines. Un autre objectif est de mieux intégrer la réalité du travail journalistique dans les travaux existants. La constitution d'un panorama des travaux, l'éventuel partage d'outils, données, benchmarks ou de résultats pourront enrichir cette réflexion\nNous sollicitons des communications portant sur n'importe aspect du journalisme computationnel, et prendre la forme d'articles courts (présentation courte, démo) ou d'articles longs. Les thèmes pourront concerner, de façon non limitative :\nLa détection d’événements,\nLe fact-checking, le décodage,\nLes études sociologiques ou historiques,\nLa fiabilité des sources,\nL’exploration d'archives de news,\nLa génération automatique de contenu journalistique,\nLa visualisation de données, la navigation dans de grandes masses de données,\nLa production participative (crowdsourcing) pour le journalisme,\nLa dissémination des nouvelles à travers les réseaux sociaux,\nLes outils “intelligents” pour les journalistes,\nLa recommandation, la personnalisation,\nLa détection de plagiat, de cliché, de biais, de propagande, de fausses informations (hoax) dans le texte, les images ou les vidéos\nL’analyse du discours politique,\nLa contextualisation de l’information,\nLa diversité des sources\n\nInformations pratiques\n----------------------\nLes propositions sont à soumettre via le site Easychair de la conférence au format EGC2017 (format RNTI latex : http://www.editions-rnti.fr/files/RNTI-X-Y2.1.zip):\n\nhttps://easychair.org/conferences/?conf=egc2017\nSélectionner le track « CompJournalisme »\n\nPeuvent être soumis des articles courts (4 pages ; présentation courte, démo) ou des articles longs (8 à 12 pages max.) présentant des travaux aboutis ou des prises de position.\n\nComité d'organisation\n---------------------\nXavier Tannier, LIMSI - Univ. Paris Sud\nLaurent Amsaleg, IRISA - CNRS\nVincent Claveau, IRISA - CNRS",
      "created_time": "2016-11-03T23:36:00+0000"
    },
    {
      "message": "Atelier ASSEMO2017 - Articles scientifiques : savoir, évaluation et modélisation\n\nEn conjonction avec le congrès EGC, Grenoble, 2017\n\nhttp://tesniere.univ-fcomte.fr/assemo2017\n\nAppel à contributions\n\nLes articles scientifiques sont au coeur des débats, qu’ils s’agissent des problématiques autour des formes d’évaluation de la recherche, de la détection d’articles générés automatiquement ou des bibliothèques scientifiques pirates. Ils montrent néanmoins les collaborations et réseaux, soulignent la reconnaissance et l’excellence et déterminent les carrières. De nouveaux modèles et vecteurs de communications se dessinent à travers l’open-accès, et de nombreux débats ont lieu autour de l’édition, des dispositifs techniques, mais aussi des outils de recherches et d’extraction d’information, d’annotation sémantique et de fouilles textuelles. Les réseaux jouent un rôle prépondérant avec les réseaux de co-citation, mais aussi selon le point de vue de la dynamique des collaborations scientifiques et des relations sociales de l’activité scientifique en contribuant à modifier la structure et les standards de l’article scientifique. Ils peuvent aider les bibliothèques numériques à visualiser les tendances scientifiques ainsi que les relations et les influences des travaux et des auteurs. L’atelier se propose de faire le point sur les dernières évolutions tant du point de vue fondamental que des applications. Cela est d’autant plus important que de nombreux ateliers, défis et campagnes d’évaluation traitant des métadonnées et/ou de l’analyse de texte intégral dans articles scientifiques ont émergé ces dernières années sur la scène internationale (ESWC Semantic Publishing Task 2014, Workshop on Scholarly Web Mining, Workshop on Mining Scientific Publications, Joint workshop on Bibliometric-enhanced IR and NLP for Digital Libraries, etc.) et nationale avec des initiatives comme le Defi EGC 2016 (Communauté EGC quelle histoire et quel avenir).\n\nObjectifs :\n\nCet atelier interdisciplinaire souhaite réunir les acteurs dont les publications et la production du savoir se trouvent être le centre d’intérêt de leurs travaux, que ce soit en informatique, en traitement automatique des langues, en science de l’information ainsi qu’en sociologie des sciences. Le but est le partage d’expérience et de savoir sur les problématiques liées à l'exploitation des articles scientifique. \n\nThématiques :\n\nRecherche d’information et fouilles textuelles d’articles scientifiques ;\nModélisation de la structure rhétorique des publications ;\nWeb sémantique et ontologie ;\nÉvaluation de la science et bibliométrie ;\nÉdition scientifique et libre accès ;\nSavoir et diffusion des connaissances ;\nAnnotations sémantiques de fonds éditoriaux scientifiques.\n\nDates importantes (dates prévisionnelles) :\n\n   Date limite de soumission des articles : 04/12/2016\n   Notification aux auteurs : 19/12/2016\n   Version finale : 08/01/2016\n   Atelier : 23/01/2017\n\nFormat de l’atelier :\n\nL'objectif de cet atelier est de favoriser des présentations et des discussions. Peuvent être soumis :\n\n   des résumés étendus (4 pages)\n   des articles longs (maximum 12 pages)\n   des propositions de démonstration logicielles (4 pages)\n\nSoumission :\n\nLa soumission de prises de position bien articulées, d’expériences industrielles et de travaux en cours sont les bienvenues et privilégiés. \n\nFormat de soumission : les soumissions seront anonymes et se feront par voie électronique exclusivement à partir du site web Easychair de la conférence au format EGC2017 (format RNTI latex : http://www.editions-rnti.fr/files/RNTI-X-Y2.1.zip):\n\nhttps://easychair.org/conferences/?conf=egc2017\nSélectionner le track « ASSEMO2017 - Articles scientifiques : savoir, évaluation et modélisation »\n\nComité d'organisation\n\nMarc Bertin, maître de conférences, Université de Toulouse\nChérifa Boukacem – Zeghmouri, maître de conférences - HDR, Université Claude Bernard Lyon 1\nGuillaume Cabanac, maître de conférences, Université de Toulouse 3\n\nComité scientifique (par ordre alphabétique)\n\nIana Atanassova,  maître de conférences - HDR, Université de Franche-Comté\nMarc Bertin, maître de conférences, Université de Toulouse\nChérifa Boukacem – Zeghmouri, maître de conférences - HDR, Université Claude Bernard Lyon 1\nGuillaume Cabanac, maître de conférences, Université de Toulouse 3\nGhislaine Chartron, Professeur, Laboratoire Dicen, CNAM\nPascal Cuxac, Ingénieur de Recherche, INIST - CNRS\nChristophe Jouis, maître de conférences, Université Paris Sorbonne Nouvelle, Service de la Présidence & LIP6/ACASA, UPMC\nBéatrice Milard, Professeur, Université de Toulouse 2 \nCyril Labbé, maître de conférences - HDR, Université Joseph Fourier",
      "created_time": "2016-11-03T23:34:50+0000"
    },
    {
      "message": "14ème édition de l'atelier Fouille de Données Complexes\n24 janvier 2017 à Grenoble\nhttp://eric.univ-lyon2.fr/~gt-fdc/afdc17/index.html",
      "created_time": "2016-11-03T23:32:31+0000"
    },
    {
      "message": "Atelier - Fouille de Textes - Text Mine\nEn conjonction avec EGC, Grenoble, 2017\nhttp://vincentlemaire-labs.fr/TM2017/\n\nDates importantes (dates prévisionnelles) :\nDate limite de soumission des articles : 04/12/2016\nNotification aux auteurs : 19/12/2016\nVersion finale : 08/01/2016\nAtelier : 23/01/2017\nSoumission :\n: https://easychair.org/conferences/?conf=textmine17 [...] (le format à utiliser est le même que pour EGC)\n[CFP...] C'est une évidence que de dire que nous sommes entrés dans une ère ou la donnée textuelle sous toute ses formes submerge chacun de nous que ce soit dans son environnement personnel ou professionnel : l'augmentation croissante de documents nécessaires aux entreprises ou aux administrations, la profusion de données textuelles disponibles via Internet, le développement des données en libre accès (OpenData), les bibliothèques et archives en lignes, les medias sociaux ne sont que quelques exemples illustrant l'évolution de la notion de texte, sa diversité et sa prolifération.\n\nFace à cela les méthodes automatiques de fouille de données (data mining), et plus spécifiquement celles de fouille de textes (text mining) sont devenues incontournables. Récemment, les méthodes de deep learning ont créées de nouvelles possibilités de recherche pour traiter des données massives et de grandes dimensions. Cependant, de nombreuses questions restent en suspens, par exemple en ce qui concerne la gestion de gros corpus textuels multi-thématiques. Pouvoir disposer d’outils d’analyse textuelle efficaces, capables de s’adapter à de gros volumes de données, souvent de nature hétérogène, rarement structurés, dans des langues variées, des domaines très spécialisés ou au contraire de l'ordre du langage naturel reste un challenge.\n\nLa fouille de textes couvre de multiples domaines comme le traitement automatique des langues, l'intelligence artificielle, la linguistique, les statistiques, l'informatique...et les applications sont très diversifiées, que ce soit la recherche d'information, le filtrage de spam, le marketing, la veille scientifique ou économique, la lutte antiterroriste ...\n\nEn France, des conférences comme TALN, CORIA, JADT par exemple sont centrées sur l'analyse et le traitement des textes, mais avec des approches plus ciblées soit TAL, soit RI, soit statistiques. Cet atelier se veut plus fédérateur autour d'approches et d'applications aussi diverses que possibles. \n\nLe but de cet atelier est de réunir des chercheurs sur la thématique large de la fouille de textes. Cet atelier vise à offrir une occasion de rencontres pour les universitaires et les industriels, appartenant aux différentes communautés de l'intelligence artificielle, l'apprentissage automatique, le traitement automatique des langues, pour discuter des méthodes de fouille de texte au sens large et de leurs applications.\nFormat de l’atelier :\nL'objectif de cet atelier est de favoriser des présentations et des discussions. Peuvent être soumis :\n\ndes résumés étendus (4 pages)\ndes articles longs (maximum 12 pages)\ndes propositions de démonstration logicielles (4 pages)\nLes contributions seront publiées sous forme d’actes en ligne (avec ISBN). La soumission de prises de position bien articulées, d’expériences industrielles et de travaux en cours sont les bienvenus et privilégiés. Des contributions portant sur l'intérêt pratique des travaux, qu'elles viennent de l'industrie ou du monde académique, ou présentant des collaborations entre les deux seraient appréciées. Le but est le partage d’expérience et de savoir sur les problématiques liées à la fouille de textes. Pour les démonstrations : une présentation orale aménagée devra être préparée (temps de présentation plus court, et temps pour effectuer la démo sur projecteur en fin de présentation). Un temps sera aussi prévu dans le programme pour les démos. \n\n* le format à utiliser est le même que pour EGC\n\nPrincipaux thèmes (liste non limitative) :\nMéthodes de traitement automatique de la langue (TAL)\nClassifications statiques de textes\nClassifications dynamiques de textes\nMéthodes d'apprentissage\nApproches par graphes\nRecherche d'information\nIndexation\nDétection d'entités nommées\nRésumé automatique\nDétection de nouveautés\nAnalyse de sentiments\n...\nListe des domaines d'application (liste non limitative) :\nFouille de documents scientifiques\nDonnées médicales\nBrevets\nAnalyse d'opinions\nMedia sociaux (Twitter…)\nVeille scientifiques\nIntelligence économique\nAppui au pilotage scientifique\nBibliométrie\nSystèmes (à base) de dialogues\n...\nProceedings: à venir \n\nContacts:\nPascal Cuxac, - INIST - CNRS",
      "created_time": "2016-11-03T23:30:41+0000"
    },
    {
      "message": "3ème atelier - Gestion et Analyse des données Spatiales et Temporelles (GAST'2017)\nhttps://gt-gast.irisa.fr/\n\nLe troisième atelier -- Gestion et Analyse des données Spatiales et Temporelles (GAST) -- sera organisé lors d’EGC 2017. Cet atelier, s’appuyant sur le Groupe de Travail GAST, vise à regrouper les chercheurs, du domaine académique et de l'industrie, qui s'intéressent aux problématiques liées à la prise en compte de l'information temporelle ou spatiale – quantitative ou qualitative – dans leurs processus de gestion et d'analyse de données (méthodes et application de l’extraction, la gestion, la représentation, l’analyse et la visualisation d’informations). \nLes propositions d’article, de projet en cours et de démonstration en relation avec ces thèmes sont les bienvenues. Les articles peuvent présenter des travaux récents, en cours ou finalisés (y compris des articles déjà publiés).\nToutes les propositions seront relues de manière constructive par au moins 2 membres du comité de programme.\n\nL’ensemble des contributions sélectionnées sera mis à disposition de la communauté au format pdf sur le site du Groupe de Travail GAST. Les auteurs des meilleures contributions seront invités à soumettre une version étendue pour le numéro spécial « Modèles, traitements et analyses dédiés aux informations spatiales et temporelles » de la Revue Internationale de Géomatique (RIG) au premier semestre 2017.\n\nThèmes de l'atelier (liste non exhaustive)\nLes soumissions attendues porteront sur les besoins, outils, problèmes, méthodes et algorithmes dédiés à l'analyse :\n\n    de données temporelles : séries temporelles, données séquentielles, etc. ;\n    de données spatiales : images satellites, numériques, données géomatiques, etc. ;\n    de données spatio-temporelles : données issues de réseaux de capteurs, traces spatio-temporelles (déplacements d’espèces vivantes, objets), vidéos, séries temporelles d'images satellites, données géomatiques horodatées, etc. ;\n    de données textuelles évoquant des aspects spatiaux et temporels, etc.\n\nLes questions suivantes pourront, par exemple, y être abordées :\n\n    intégration de connaissances spatiales et temporelles dans un processus de fouille de données ;\n    modélisation de l'information spatiale et temporelle, prise en compte des aspects hétérogène, multidimensionnel ou multi-échelle des données temporelles et spatiales ;\n    données géo-spatiales et géo-temporelles du Web et de l'Open Data ;\n    construction et acquisition de connaissances géo-spatiales/géo-temporelles à partir de textes et/ou d’images ;\n    abstraction des données spatiales et temporelles ;\n    reconstruction/complétion/désambiguïsation/enrichissement de l'information ;\n    recherche d’informations spatiales et temporelles ;\n    méthodes de prédiction/pronostic pour les données spatiales et temporelles ;\n    mesure de qualité sur les données spatiales et temporelles ;\n    visualisation de données et de motifs spatiaux et temporels ;\n    évaluation des outils, ressources et connaissances spatiales et temporelles.\n\nTout domaine d'application, présenté sous la forme de défis prospectifs, de problème en cours ou d'illustration d'une méthode peut être présenté lors de l'atelier, par exemple :\n\n    applications en santé (monitoring de patients, suivis spatio-temporel épidémiologique, surveillance, self-monitoring) ;\n    applications liées à l’environnement (données géomatiques, images de télédétection, données de transport public, documents liés à l’aménagement) ;\n    applications commerciales (CRM, géolocalisation des « sujets chaud », recommandation mobile et spatialisée) ;\n    applications aux analyses d'images vidéos (vidéos surveillance, parcours clients en magasin) ;\n    autres applications innovantes utilisant des données spatiales ou temporelles.\n\nLes questions éthiques et pratiques relatives à l'utilisation des données spatiales et temporelles sont également des sujets d'intérêt pour l'atelier.\nDates importantes (et strictes)\n\n    Date limite de soumission :4 décembre 2016\n    Notification aux auteurs : 15 décembre 2016\n    Version finale : 05 janvier 2017\n    Atelier : 24 janvier 2017\n\nSoumissions\nLes soumissions respecteront le format RNTI des articles de EGC : http://www.editions-rnti.fr/files/RNTI-X-Y2.1.zip\nLes auteurs veilleront à avoir un nombre raisonnable de pages, mais nous n'imposons pas de limite de longueur rigide. (pour indication, les articles de la conférence sont limités à 12 pages max.)\nEn cas de démonstration, la soumission contiendra un court paragraphe pour présenter le contenu de la démonstration qui compléterait une présentation.\n\nLes soumissions seront transmises par mail aux organisateurs : thomas.guyet@irisa.fr, eric.kergosien@univ-lille3.fr, christian.sallaberry@univ-pau.fr et cyril.de-runz@univ-reims.fr \n\nLe organisateurs, C. Sallaberry, T. Guyet, E. Kergosien, C. de Runz",
      "created_time": "2016-11-03T23:28:39+0000"
    },
    {
      "likes": [
        {
          "id": "1393847514268872",
          "name": "Hafsa Ben Rjab"
        }
      ],
      "message": "Les inscriptions à la 17ème conférence EGC se déroulera à Grenoble du 24 au 27 janvier (http://egc2017.imag.fr/) sont ouvertes à :\nhttp://inscription.egc.asso.fr/EGC2017",
      "created_time": "2016-11-03T23:25:02+0000"
    },
    {
      "likes": [
        {
          "id": "426491407546790",
          "name": "Nouna Bnj"
        }
      ],
      "message": "2ndCFP Défi EGC2017 : mise à disposition de nouvelles données\n\nAvec nos excuses en cas de réceptions multiples\n\n===================================================================\n\nImportant : Mise à disposition de données supplémentaires\n\nEn complément du premier jeu de données diffusé an Avril 2016 et comportant les fichiers X_geoloc_egc_t1.csv, X_tree_egc_t1.csv  et Y_tree_egc_t1.csv, un second jeu  de données X_geoloc_egc_t2.csv, X_tree_egc_t2.csv  et Y_tree_egc_t2.csv est à présent disponible sur le site https://egc2017.imag.fr/defi. Il s’agit de données supplémentaires ayant le même format que le jeu 1.\n\nUn troisième jeu, utilisé pour évaluer les soumissions sur la première tâche (Prédiction de défaut), sera diffusé fin août. Il comportera uniquement les fichiers X_geoloc_egc_t3.csv et X_tree_egc_t3.csv. Les participants à cette tâche de prédiction devront renvoyer en plus de leur article, un fichier de résultats contenant leur prédiction et respectant le format des fichiers Y_tree_egc_t1.csv et Y_tree_egc_t2.csv. La version finale de la soumission devra donc  prendre la forme d'une archive zip ou tgz contenant le fichier résultat (fichier csv) et les sources de l’article (fichiers tex, images, styles RNTI éventuellement) et un fichier pdf de contrôle.\n\nDéfi 2017 : Un défi vert pour Grenoble !\n\nPour cette seconde édition du défi EGC,  Big Datext (http://www.big-datext.com), entreprise Grenobloise spécialisée dans l’analyse prédictive, et la mairie de Grenoble se sont toutes deux impliquées dans la mise en place et la diffusion de la base de données du challenge. En phase avec la politique Open Data de la Ville, visant à diffuser les données publiques de la métropole, Big Datext et les services de la Ville ont souhaité axer le défi sur les données relatives aux espaces verts.\n\nDonnées :\nLes données concernent des arbres situés dans la ville de Grenoble et entretenus par les services municipaux. Chaque enregistrement concerne un arbre et comporte des variables décrivant son type, son stade de développement, sa localisation et son environnement, son état et les traitements préconisés.\n\n\nObjectifs :\nLe but de ce défi est double.\nLa première tâche consiste à déterminer, à partir des données disponibles,  si l’arbre a un défaut  et dans l’affirmative lequel.\nLa seconde tâche, plus ouverte, vise à appliquer des techniques d'extraction et de gestion de connaissances afin de mieux connaitre l’état du « parc végétal » de Grenoble, de mieux comprendre son évolution et de fournir des préconisations pour faciliter son entretien. Pour cette seconde tâche, les participants peuvent s’ils le souhaitent avoir recours à des données externes.\n\nLes participants peuvent traiter au choix l’une des deux  tâches ou les deux et, un retour sur la qualité des données (complétude, redondance, etc) dans un contexte open data sera appréciée.\n\nSoumission :\nPour répondre au défi, vous devez rassembler vos résultats sur ces données dans  un article long  soumis à la conférence EGC’2017  avec la mention \"Défi EGC 2017\" dans le titre. Le format à utiliser est la dernière version du style LaTeX RNTI :\nhttp://www.editions-rnti.fr/files/RNTI-X-Y2.1.zip\nLes modalités de soumission et d’acceptation sont les mêmes que pour les autres articles EGC, notamment l’anonymat des soumissions.\n\nDe plus les participants au premier défi devront renvoyer un fichier de résultats contenant leur prédiction pour un jeu d’évaluation qui sera fourni fin août. La version finale de la soumission devra donc  prendre la forme d'une archive zip ou tgz contenant le fichier résultat (fichier csv) et les sources de l’article (fichiers tex, images, styles RNTI éventuellement) et un fichier pdf de contrôle.\n\n \n\nLes fichiers des données au format CSV ainsi que le descriptif des variables (EGC_description_variables_14042016.xls, classeurs EGC et Prédiction) et les consignes pour la tâche de prédiction sont disponibles sur le site : https://egc2017.imag.fr/defi\n\n \n\nPrésentation :\nLes papiers acceptés seront présentés lors de la conférence à Grenoble  en janvier 2017, très certainement dans une session spéciale « Défi EGC ».\n\nAttribution du prix du défi EGC 2017 : 1500 euros\nUn jury se réunira pour attribuer le prix du défi EGC 2017, dans le même esprit que pour les autres prix EGC. Les critères d’attribution  seront en particulier la pertinence et la qualité de l'approche méthodologique ainsi que l'originalité et l'intérêt des résultats obtenus.\n\nCalendrier : Les dates de soumission et de notification seront les mêmes que pour la conférence EGC 2017\n\nContact :  Vous retrouverez tous les éléments du Défi-EGC sur la page dédiée du site de l’association EGC. http://www.egc.asso.fr/\n \nSi vous avez d’autres questions, merci de contacter Christine Largeron (largeron@univ-st-etienne.fr) en indiquant clairement « Défi EGC 2017» dans le sujet de votre mail.",
      "created_time": "2016-07-12T11:53:46+0000"
    },
    {
      "message": "5ème édition des journées « Big Data Mining and Visualization »\n\nJeudi 23 et vendredi 24 juin 2016\n\nAmphi A, Ile du Saulcy, Metz\n\nhttp://eric.univ-lyon2.fr/~gt-fdc/journees/\n\nAttention ! L’inscription est gratuite mais obligatoire avant le mardi 14 juin 2016 sur le site suivant (l’inscription inclut les déjeuners et les pauses) : Inscriptions\n\n \n\n \n\n\nProgramme\n\n \n\nJeudi 23 juin\n\n \n\n9H30-10H00   Accueil et café\n\n \n\n10H00-10H15 Introduction aux journées\n\n \n\n10H15-11H15 Conférencier invité Ahcène Bounceur, (Lab-STICC -Université de Bretagne Occidentale) : “CupCarbon: A New Platform for Designing and Simulating Smart-City & IoT Wireless Sensor Networks”  (Présidence de session Lydia Boudjeloud)\n\n \n\n11H15-12H15 Session 1 : Données complexes (Présidence de session Germain Forestier)\n\n \n\n11H15 -11H15 Tianatahina Jimmy Francky Randrianasoa, Construction d’Arbres Binaires de Partitions Multi-critères pour la segmentation d’images satellites\n\n \n\n11H45-12H15 François Meunier, Christophe Marsala and Laurent Castanié, Heat Kernel Signature pour la sélection et la classification d’objets - application aux géo-modèles 3D\n\n \n\n12H15 - 14H00 Repas\n\n \n\n14H00-16H00 Session 2 : Données massives (Présidence de session Cyril de Runz)\n\n \n\n14H - 14H30 Massinissa Saoudi, Massinissa Lounis, Ahcène Bounceur, Reinhardt Euler and Tahar Kechadi. A Parallel Data Mining Algorithm for PageRank Computation\n\n \n\n14H30-15H00 Ahmed Masmoudi, Lobna Bouchaala, Mounir Ben Ayed, Apprentissage automatique à partir des données massives pour un système d'aide à la décision médicale : Application pour le diagnostic précoce de la maladie d’Alzheimer\n\n \n\n15H00 – 15H30 Francesca Iannuzzi and Franck Avenel, Territorial Watch for the Public Administration\n\n \n\n15H30 - 16H00 Discussion autour d’un café\n\n \n\n16h00-17h00 Cyril De Runz : Défi EGC \n\n \n\n \n\nVendredi 24 juin\n\n \n\n9H00-10H00 Accueil et café\n\n \n\n10H00-11H00 Conférencier invité Christophe Hurter, (ENAC Ecole Nationale de l’Aviation Civile – Toulouse) : ”Interactive Multidimensionnel Data Exploration” (Présidence de session Pierrick Bruneau)\n\n \n\n11H15- 11H30 pause-café\n\n \n\n10H30-12H00 Session 3 : Visualisation de données  (Présidence de session Brieuc Conan-Guez)\n\n \n\n10H30 – 11H00 Ibrahim Louhi, Lydia Boudjeloud and Thomas Tamisier. Clustering de Données Massives par Approches de Flux de Données\n\n \n\n11H00 – 11H30 Ulrich Leopold  The Smart City and Region Platform - Une plateforme d'analyse et de simulation géospatiale basée sur l'interopérabilité et les technologies de calcul distribué\n\n \n\n11H30- 12H00 Alma Cantu, Olivier Grisvard and Thierry Duval. Modèle de caractérisation des visualisations de données complexes en grandes quantités\n\n \n\n12H00 - 14H00 Repas\n\n \n\n14H00- 15H00 Conférencier invité Yanik Ngoko, (Qarnot Computing) : “Une approche d’Edge Computing pour la décentralisation de l’Internet des Objets” (Présidence de session Mustapha Lebbah)\n\n \n\n15H00- 17H00 Session 4 : Industriels  (Présidence de session Alain Gély)\n\n \n\n15H00- 15H30 Jean-Valère Cossu and Christophe Navas. Vodkaster, applications small et big data analytics\n\n \n\n15H30-16H00 Carlos Sanin Quiroz. Clustering de données Twitter pour l’analyse des cycles de vie des articles de médias\n\n \n\n16H00-17H00 Discussion et clôture des journées\n \n\n\n\nComité d’organisation :\n\nLydia Boudjeloud-Assala (LITA – Université de Lorraine)\n\nAlain Gély (LITA – Université de Lorraine)\n\nBrieuc Conan-Guez (LITA – Université de Lorraine)\n\nAlexandre Blansché (LITA – Université de Lorraine)\n\n \n\nComité de coordination :\n\nCorrespondant EGC avec les groupes de travail :\n\nMustapha Lebbah (LIPN, Université Paris 13)\n\nGT-FDC :\n\nCécile Favre (ERIC, Université Lyon 2)\n\nGermain Forestier (MIPS, Université de Haute Alsace)\n\nCamille Kurtz (LIPADE, Université Paris Descartes)\n\nGT-GGB :\n\nEtienne Birmelé,  (MAP5 – Université Paris Descartes)\n\nMohamed Elati (iSSB – Université Evry Val d’Essonne)\n\nBlaise Hanczar (IBISC -  Université Evry Val d’Essonne)\n\nGT-GAST :\n\nThomas Guyet (IRISA, Agrocampus Ouest)\n\nEric Kergosien (GERIICO, Université Lille 3)\n\nCyril de Runz (CReSTIC, Université de Reims Champagne-Ardenne)\n\nGT-VIF :\n\nHanene Azzag (LIPN, Université Paris 13)\n\nDavid Bihanic (CALHISTE, Université de Valenciennes et du Hainaut-Cambrésis)\n\nMonique Noirhomme (FUNDP, Namur, Belgique)\n\nFabien Picarougne (LINA, Université de Nantes)\n\nGilles Venturini (LI, Université de Tours)",
      "created_time": "2016-06-06T11:24:42+0000"
    },
    {
      "message": "Bonjour à toutes et à tous,\n\n\nNous avons le plaisir de vous annoncer le lancement de la quatrième\nédition du prix de thèse de l'association EGC. Ce prix 2017 a pour\nobjectif de récompenser la meilleure thèse soutenue dans les\nthématiques liées à l'Extraction et la Gestion des Connaissances.\n\n\nLe prix est doté d'une somme de 500 euros, d'une inscription gratuite à\nla conférence EGC avec prise en charge du déplacement/hébergement (2\nnuits), et d'une invitation à présenter les principaux résultats de\nla thèse à la conférence EGC 2017 à Grenoble.\n\n\n*******Dates importantes pour le prochain prix\n\n*******Date limite de réception des dossiers : 10 octobre 2016\n\n*******Examen des dossiers par le jury : début décembre 2016\n\n*******Remise du prix : lors de la conférence EGC 2017 à Grenoble\n\n\nLe lien de soumission :\n\nhttps://easychair.org/conferences/?conf=egc2017\n\n\nVous trouverez les renseignements nécessaires sur le site de\nl'association EGC\nhttp://www.egc.asso.fr/Manifestations_dEGC/67-FR-Reglement_du_prix_de_these_de_lassociation_EGC\n\n\nPour tout renseignement, n'hésitez pas à contacter Hanene Azzag,",
      "created_time": "2016-06-01T08:00:27+0000"
    },
    {
      "likes": [
        {
          "id": "630321027070239",
          "name": "Nourhène Bri"
        }
      ],
      "message": "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n\nAPPEL A COMMUNICATIONS EGC 2017\n17ème conférence francophone sur\nl'Extraction et la Gestion des Connaissances\ndu 24 au 27 janvier 2017 - Grenoble\n\nhttp://egc2017.imag.fr/ \n\n\"Vers une extraction et un traitement diffus\ndes connaissances.\"\n\n* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n\n\nLa conférence Extraction et Gestion des Connaissances (EGC) est un événement annuel réunissant des chercheurs et praticiens de disciplines relevant de la science des données et des connaissances. Ces disciplines incluent notamment l’apprentissage automatique, l’ingénierie et la représentation des connaissances, les statistiques et l’analyse de données, la fouille de données, les systèmes d’information, les bases de données, le Web sémantique et les données ouvertes, etc..\n\nLe traitement et l’intégration de sources de données et de connaissances posent sans cesse de nouveaux besoins en termes de méthodes, de techniques et d’outils pour acquérir les données, les classifier, les intégrer, les représenter, les stocker, les indexer, les visualiser, interagir avec elles, les protéger et surtout les transformer en connaissances utiles, pertinentes et respectueuses de nos droits.\n\nPar exemple, après la multiplication des sources de données en réseau, notamment sur le Web, nous nous préparons maintenant à un déploiement diffus de l’extraction et du traitement des connaissances. Après la connexion des personnes par les réseaux sociaux, ce sont les objets connectés qui ajoutent non seulement de nouvelles sources de données mais aussi de nouvelles architectures de traitement et gestion de connaissances.\n\nLes applications connectées à ces réseaux privés et publics ont à gérer, intégrer et traiter des données de plus en plus nombreuses et variées. Aux besoins de passage à l’échelle posés par de grandes collections de données, s'ajoutent les besoins de traitement de données hétérogènes, de qualité variable et parfois très dynamiques allant de l’article de journal en ligne, à la température d’un capteur connecté, de la photo ou la vidéo virale à la position géographique de nos voitures, des messages courts d’un microblog aux données liées d’une base de génomique, etc.\n\nLa conférence EGC est l’occasion de faire se rencontrer des spécialistes du monde entier issus des milieux académique et industriel, privé et public, afin de confronter des travaux théoriques et des applications pratiques sur des données réelles et de communiquer des travaux de qualité, d'échanger et de favoriser la fertilisation croisée des idées, à travers la présentation de travaux de recherche récents, de développements industriels et d'applications originales.\n\nLes actes d’EGC 2017, comprenant les articles des communications orales ainsi que ceux associés aux posters, aux démonstrations et aux défis, paraîtront dans un numéro de la revue RNTI. Les auteurs des meilleurs articles seront invités à soumettre une version étendue de leurs articles pour être publiés dans des post-actes internationaux édités chez Springer.\n\nNous vous invitons dès à présent à préparer et planifier vos propositions d'articles.\n\n\n\nSoumission :\n------------\n\nPlusieurs types de communications sont possibles (les démonstrations de logiciels, défi et ateliers thématiques font l'objet d'appels à contributions spécifiques) :\n\n- travaux de recherche originaux (académiques ou applicatifs/industriels) publiés sous forme d’articles longs de 12 pages, d’articles courts de 6 pages ou de posters accompagnés de résumés de 2 pages, selon leur maturité. Chaque article accepté (long ou court) sera présenté lors de la conférence via une communication orale et les auteurs pourront, s'ils le souhaitent, accompagner leur communication par un poster.\n\n- travaux de recherche déjà publiés dans de bonnes conférences internationales mais inédits en français (publiés sous forme de résumé de 6 pages obligatoirement en français)\n\n- un défi à la communauté intitulé \"Un défi vert pour Grenoble !\" sous la forme d'un article long (12 pages), plus d'information sur l'appel à contributions spécifiques au défi http://egc2017.imag.fr/defi \n\n- démonstrations de logiciels où la démonstration est complétée d'un article de 4 à 6 pages : voir appel à soumissions spécifique aux démonstrations sur le site.\n\n- ateliers thématiques : voir appel à soumissions spécifique aux ateliers sur le site.\n\nLes articles peuvent être soumis en français ou en anglais mais en cas d'acceptation, l'article devra être traduit en français sauf pour les articles où les auteurs sont non-francophones.\nUne vérification de la traduction pourra être effectuée et le comité de programme se réserve le droit de rejeter un article suite à cette étape.\n\nFormat de soumission : les soumissions seront anonymes et se feront par voie électronique exclusivement à partir du site web de la conférence :\nhttp://egc2017.imag.fr/ \n\nElles devront être envoyées au format pdf exclusivement et devront impérativement utiliser le format RNTI latex accessible via le site web de la conférence. Les soumissions qui dépasseraient 12 pages ou qui ne respecteront pas le format RNTI Latex ne seront pas évaluées.\n\n\n\nPrix :\n------\n\nCinq prix scientifiques seront attribués lors de la conférence :\n- un prix pour la catégorie \"article académique\" (1500 euros),\n- un prix pour la catégorie \"article applicatif\" (1500 euros),\n- un prix pour le défi (1500 euros),\n- un prix pour la catégorie \"démonstration\" (500 euros),\n- un prix de thèse (500 euros) décerné à un jeune docteur dont la thèse a été soutenue depuis moins de trois ans dans les thématiques liées à l’extraction et la gestion des connaissances.\n\nCes prix seront décernés par un jury composé de membres du comité de pilotage. Le prix de thèse fait l’objet d’une annonce spécifique.\n\n\n\nDates importantes\n-----------------\n\nCes dates concernent les articles académiques ou applicatifs/industriels, les travaux de recherche déjà publiés dans des conférences internationales mais inédits en français ainsi que le défi EGC. Pour les ateliers et les démonstrations, voir les appels à communications spécifiques. Ces dates sont fermes et définitives.\n\n- Résumés des articles : 7 octobre 2016  - 11:00 AM Paris\n- Textes complets des articles : 14 octobre 2016 - 11:00 AM Paris\n- Interactions auteurs/membres Comité de Programme : 14-16 novembre 2016 - 11:00 AM Paris\n- Notification aux auteurs : 25 novembre 2016 - 11:00 AM Paris\n- Version finale des articles : 11 décembre 2016 - 11:00 AM Paris\n\n\n\nOrganisation\n-------------\n\nPrésident du Comité de Programme :\n     Fabien Gandon, UCA, Inria, CNRS, I3S, Wimmics\n\nPrésident du Comité d'Organisation :\n     Gilles Bisson, CNRS, AMA\n\n\n\t \nThématiques :\n-------------\n\nLes sujets d’intérêt de la conférence incluent (liste non-exhaustive) :\n\n* Fondements de l’extraction et de la gestion de connaissances\n\n- apprentissage supervisé : apprentissage de règles, apprentissage statistique, modèles probabilistes, méthodes d'ensembles, régression, évaluation de classifieurs, classes déséquilibrées.\n- apprentissage non supervisé : méthodes de partitionnement et de recouvrement, méthodes hiérarchiques, multi-vues, multi-stratégies, co-clustering\n- méthode de découverte de motifs et d'ensembles de motifs : séquences, graphes, tenseurs.\n- méthodes incrémentales de fouille de données\n- cadre théorique pour la fouille de données, langages de requêtes déclaratifs pour la fouille de données, fouille de données sous contraintes\n- algorithmes de fouille de données robustes au passage à l’échelle, systèmes distribués / parallèles pour la fouille de données\n- détection d'exceptions, d'inattendus, d'anomalies, de signaux faibles.\n- préservation de la confidentialité et de l'anonymat\n- méthodes statistiques en fouille de données\n- programmation logique inductive\n- apprentissage topologique, variétés mathématiques\n- fouille visuelle de données\n- analyse des données symboliques\n- représentation, traitement et échange de données et connaissances sur le Web: formalisation sur le Web sémantique, données liées, Web de données, données ouvertes, publication de données, interrogation et raisonnement sur le Web sémantique, traçabilité et validation des données sur le Web\n- variété des données et données complexes : données structurées, semi-structurées, textuelles ; données temporelles, spatiales, géolocalisées ; données multimedia ; données relationnelles ; données en réseau, en graphes ; données dynamiques ; flux de données ; données annotées à l'aide d'ontologies ; données hétérogènes sémantiquement\n\n\n* Aspects méthodologiques de l’extraction et de la gestion de connaissances\n\n- acquisition, recueil, pré-traitement des données, filtrage, réduction de données, sélection et modification des caractéristiques\n- critères et évaluation de la qualité des données, des connaissances extraites\n- intégration de données (entrepôt, OLAP, médiation,...)\n- intégration de connaissances dans le processus d'extraction (ontologies, expertise,...)\n- gestion des connaissances et d'ontologies (acquisition, stockage, mise à jour, interopérabilité, interconnexion, évolution)\n- assister le cycle de vie des vocabulaires (ontologies, thésaurus, etc.) sur le Web (modèles du Web sémantique, conceptualisation, formalisation, publication, accès, comparaison, évaluation, alignement, etc.)\n- préparation, architecture et modèles de données pour liées sur le Web.\n- visualisation analytique, interaction homme-machine en fouille de données\n- traçabilité, sécurité et intégrité de l'information et des données\n- plateformes et systèmes pour l'ECD\n- protocoles d'évaluation et validation de modèles à partir d'utilisateurs\n- études expérimentales sur des données volumineuses\n\n\n* Extraction et gestion de connaissances dans des domaines émergents\n\n- analyse de liens, communautés en ligne, réseaux sociaux, médias sociaux.\n- fouille de données d'opinions, de dépêches, de microblogging\n- mobilité, géo-localisation, découverte de connaissances et ubiquité, intelligence ambiante, réseaux de capteurs, internet des objets\n- Big Data et nouveaux paradigmes de traitement des données :  calcul haute performance, parallélisme, systèmes distribués\n- crowdsourcing, modélisation de comportements\n- fouilles du Web de données, extractions pour le Web sémantique, annotation de ressources multimédia pour le Web, annotation du Web des Objets\n- fertilisation croisée entre extraction de connaissances et autres domaines de recherche ou d'applications : intelligence artificielle, sciences sociales et humanités numériques, traitement automatique des langues, vision par ordinateur.\n\n\n* Applications de l'extraction et de la gestion de connaissances\n\n- développement durable, transports et lieux intelligents\n- informatique verte pour la gestion et l'extraction de connaissances\n- modélisation des épidémies, recherche clinique, médecine, biologie\n- détection d'intrusion, prévention de fraude, sécurité\n- mémoires d'entreprise, veille technologique, intelligence économique\n- système de recommandation, commerce électronique, publicité en ligne\n- applications dans d'autres domaines comme la chimie, l'environnement, les sciences sociales, l'éducation, l'économie, la finance, le tourisme, la défense, le génie logiciel.",
      "created_time": "2016-06-01T07:57:21+0000"
    },
    {
      "likes": [
        {
          "id": "10153500769602118",
          "name": "Cyril de Runz"
        },
        {
          "id": "617194565039337",
          "name": "Yarabi Ljanna"
        }
      ],
      "message": "L’association Extraction et Gestion des Connaissances (EGC) a l’honneur d’attribuer le prix de la « Meilleure Démonstration\nd’EGC’2016 » à :\nNicolas Lachiche, Alain Shakour\n\npour leur travail intitulé\n\nNouveaux algorithmes de fouilles de données relationnelles de clowdflows",
      "created_time": "2016-01-24T15:29:56+0000"
    },
    {
      "likes": [
        {
          "id": "10153500769602118",
          "name": "Cyril de Runz"
        }
      ],
      "message": "L’association Extraction et Gestion des Connaissances (EGC) a l’honneur d’attribuer le prix du « meilleur article défi d’EGC’2016 » à :\nAdrien Guille, Edmundo-Pavel Soriano-Morales, Ciprian-Octavian Truica\n\npour leur travail intitulé\n\nTopic modeling and hypergraph mining to analyze the EGC conference history",
      "created_time": "2016-01-24T15:29:32+0000"
    },
    {
      "message": "L’association Extraction et Gestion des Connaissances (EGC) a l’honneur d’attribuer le prix du « meilleur article applicatif d’EGC’2016 » à :\nRabah Mazouzi, Rabih Taleb, Lynda Seddiki, Cyril de Runz, Kevin Guelton, Herman Akdag\n\npour leur travail intitulé\n\nUne approche basée sur des données mixtes – mesures et estimations – pour la détection de défaillances d’un système robotisé",
      "created_time": "2016-01-24T15:29:13+0000"
    },
    {
      "likes": [
        {
          "id": "10153500769602118",
          "name": "Cyril de Runz"
        },
        {
          "id": "617194565039337",
          "name": "Yarabi Ljanna"
        }
      ],
      "message": "L’association Extraction et Gestion des Connaissances (EGC) a l’honneur d’attribuer le prix du « meilleur article académique d’EGC’2016 » à :\nArnaud Giacometti, Arnaud Soulet\n\npour leur travail intitulé\n\nDétection de données aberrantes à partir de motifs fréquents sans énumération exhaustive",
      "created_time": "2016-01-24T15:28:55+0000"
    },
    {
      "likes": [
        {
          "id": "10153500769602118",
          "name": "Cyril de Runz"
        },
        {
          "id": "617194565039337",
          "name": "Yarabi Ljanna"
        }
      ],
      "message": "L’association Extraction et Gestion des Connaissances (EGC) a l’honneur d’attribuer son prix de thèse 2016 à :\n\nJulio Cesar Dos Reis\n(Brazil, IC/UNICAMP)\n\npour son travail intitulé\n\u000bAdaptation des Mappings entre Systèmes d'Organisation de la Connaissance du domaine Biomédical",
      "created_time": "2016-01-24T15:28:12+0000"
    },
    {
      "message": "Toutes nos excuses en cas de réceptions multiples.\n* * * * * * * * * * * * * * * * * * * * * * * * * * * *\n\n                APPEL A PARTICIPATIONS\n\n                    EGC 2016\n\n              http://egc2016.univ-reims.fr\n\n               18-22 janvier 2016 - Reims\n\n* * * * * * * * * * * * * * * * * * * * * * * * * * * *\n\n\nLa 16ème conférence sur l'Extraction et Gestion des Connaissances (EGC 2016) aura lieu à Reims du 18 au 22 janvier 2016.\n\nL’objectif des conférences EGC est de rassembler des chercheurs de disciplines relevant de l’extraction et la gestion de connaissances (apprentissage automatique, ingénierie et représentation des connaissances, statistique et analyse de données, fouille de données, systèmes d’information, bases de données) et des spécialistes du monde industriel et des entreprises qui déploient des méthodes d’extraction et de gestion de connaissances sur des données réelles, afin de communiquer des travaux de qualité, d'échanger et de fertiliser des idées nouvelles.\n\nDepuis plusieurs années, nous assistons à une explosion des données disponibles.  De nouvelles sources de données prometteuses, telles que le web social ou le web des données liées sont apparues. Les applications sont confrontées à des données de plus en plus nombreuses et variées et suscitent de nouveaux besoins en termes de méthodes, de techniques et d’outils pour acquérir les données, les classifier, les intégrer, les représenter, les stocker, les indexer, en extraire des connaissances pertinentes et les visualiser.  L'essor de la science des données fait ressortir de nouveaux besoins comme la capacité à traiter de grandes collections de données hétérogènes, dynamiques, de qualité plus ou moins bonne ou la nécessité de méthodes interactives. Les nouveaux développements issus des différentes évolutions de ces domaines doivent être évalués et mis en regard avec les approches précédentes. Les différents thèmes de la conférence EGC 2016 ont pour objectif de couvrir l’ensemble de ces aspects.\n\nLa conférence EGC, rendez-vous majeur de la communauté d’extraction et de gestion de connaissances en France, est ouverte à la présentation de travaux de recherche récents, de développements industriels et d'applications originales dans le domaine de l’extraction et de la gestion des connaissances.  Elle permet ainsi d’exposer des résultats de travaux théoriques et appliqués et d’échanger autour de ces derniers.\n\nEGC 2016 a le plaisir d'accueillir les conférenciers invités suivants :\n\n    Toon Calders (Président d'honneur) - Université Libre de Bruxelles, Belgium : Fairness-Aware Data Mining\n    Pascal Buléon - CNRS Université de Caen Normandie, France\n    Marcin Detyniecky - AXA Data Innovation Lab, France : Extraction de connaissances liées aux nouveaux défis de l’assurance\n    Sašo Džeroski - Jožef Stefan Institute, Ljubljana, Slovenia : Learning from Massive, Incompletely annotated & Structured Data\n    Jérôme Euzenat - INRIA et Université Grenoble-Alpes, France : Extraction de clés de liage de données\n    Tias Guns - KU Leuven, Belgium : Towards generic and efficient constraint-based mining, a constraint programming approach\n\n\nLe programme scientifique se compose d'articles et démonstrations\nqui sont indiqués à :\nhttp://egc2016.univ-reims.fr/index.php/Papiers_accept%C3%A9s\n\nainsi que de 7 ateliers (le 19 janvier) pour lesquels les appels\nà soumission sont encore ouverts :\nhttp://egc2016.univ-reims.fr/index.php/Ateliers_EGC2016\n\n .   CluClo2016    Clustering and Co-clustering\n .   GAST2016    Gestion et Analyse des données Spatiales et Temporelles\n .   FDC2016    Fouille de données complexes dans un processus d'extraction de connaissances\n  .  QLOD2016    Qualité des Données du Web\n  .  DPS2016    Données participatives et sociales – Quels liens fouille de données et intelligence artificielle ?\n  .  GGB2016    Grands Graphes et Bioinformatique\n  .  VIF2016    Visualisation d'informations, Interaction, et Fouille de données\n\nDe plus, cinq prix scientifiques seront attribués lors de la conférence\nhttp://egc2016.univ-reims.fr/index.php/Prix_EGC\n\nNous vous invitons dès maintenant à vous inscrire à EGC 2016 :\nhttp://egc2016.univ-reims.fr/index.php/Inscription\n\nEn espérant vous voir sur Reims du 18 au 22 janvier 2016,\n\n\nPrésident du Comité de Programme :\nBruno Crémilleux - GREYC - Université de Caen Basse-Normandie\n\nPrésident du Comité d'Organisation:\nCyril de Runz, CReSTIC, Université de Reims Champagne-Ardenne",
      "created_time": "2015-12-08T13:21:49+0000"
    },
    {
      "likes": [
        {
          "id": "939222382767398",
          "name": "Yaba Gigi"
        },
        {
          "id": "1554755874813762",
          "name": "Association EGC - Extraction et Gestion des Connaissances"
        }
      ],
      "message": "Les inscriptions pour EGC 2016 à Reims sont ouvertes : http://egc2016.univ-reims.fr/index.php/Inscription",
      "created_time": "2015-11-01T22:25:55+0000"
    },
    {
      "message": "Données participatives et sociales – Quels liens entre fouille de données et intelligence artificielle ?\n\n\nCes dernières années ont été marquées par l’explosion des données participatives et sociales sur les nouveaux médias. Ces données sont au coeur de nouveaux défis tant au niveau de la fouille de données que de l'intelligence artificielle (IA). Les travaux de la littérature sont généralement associés à l'une des deux communautés, sans mettre en exergue le lien entre elles. Cet atelier cherche particulièrement à focaliser sur le lien entre fouille de données et IA pour traiter les données participatives et sociales, tant du point de vue représentation qu'analyse.\n\nL’objectif de cet atelier est de permettre aux chercheurs, industriels et étudiants de présenter et échanger sur les problématiques actuelles motivées par ces données participatives et sociales.\nCet atelier vise à réunir des contributions scientifiques, et à échanger des points de vue et retours d’expériences, sur le thème de l'utilisation de techniques d'intelligence artificielle et de fouille de données pour le traitement de données participatives et sociales.\n\n\nPlus d'information sur le site web de l'atelier :  http://people.irisa.fr/Arnaud.Martin/atelierDPS/ \n\nDates importantes : \n\n    30 novembre 2015 : Date limite de réception des propositions\n    10 décembre 2015 : Notification aux auteurs\n    16 décembre 2015 : Mise en ligne du programme\n    19 janvier 2016 : Atelier\n\nInstructions aux auteurs :\nLes articles, sous forme de résumé étendu, ne doivent pas dépasser 2 pages en suivant les modèles LaTeX RNTI disponibles à cette adresse (http://www.editions-rnti.fr/files/RNTI-X-Y2.1.zip). Ils pourront présenter soit des recherches en cours, soit des recherches abouties.\n\nLes auteurs sont invités à soumettre leurs communications au format PDF sur EasyChair à l'adresse suivante https://easychair.org/conferences/?conf=dps2016.\n\nComité d'organisation :\n\n    Arnaud Martin, IRISA, Université de Rennes 1\n    Engelbert Mephu Nguifo, LIMOS, Clermont Université",
      "created_time": "2015-10-27T11:10:51+0000"
    },
    {
      "message": "Atelier Qualité des Données du Web (QLOD’16) - EGC 2016\nAppel à communications\n\n\nAujourd'hui, avec le développement des technologies du web, la donnée est considérée comme un atout stratégique pour les organisations, les laboratoires scientifiques et les entreprises. La disponibilité des données dans un format numérique et structuré a accéléré le développement des techniques d'exploration et de raisonnement sur les données dans le but d'extraire de valeur ajoutée à partir de ces données. Ces approches ont créé un besoin pour des données réelles, fiables et de haute qualité. En conséquence, la qualité des données est devenue un enjeu important et un défi pour les années à venir.\nLa recherche dans ce domaine comprend des aspects théoriques, liés à la formalisation, la définition de la qualité et le développement de langages et de modèles supportant les concepts sous-jacents. Elle couvre aussi des recherches pratiques, expérimentales et comme le développement de méthodes d'évaluation, les approches de validation, les benchmarks, l'expérimentation sur des jeux réels, etc. \n\nQLOD'16 vise à offrir un espace pour des échanges fructueux et enrichissants impliquant des chercheurs, mais aussi des professionnels du monde de l'entreprise avec une diversité de point de vue et de profil concernant la qualité des données surtout lorsqu'elles sont hétérogènes, non/peu structurées, massives et de qualités diverses. Les présentations peuvent porter sur des travaux scientifiques, des réalisations pratiques, ainsi que sur des projets en cours ou réalisés mettant en évidence les défis et les solutions proposées. Les travaux présentant des cas d'utilisation seront particulièrement appréciés, tout comme le seront les démonstrations de logiciel associées le jour de l'atelier.\n\nThèmes de l'atelier (liste non exhaustive) :\n\nL'atelier ne se restreint pas à un ensemble de thèmes. Le problème de la qualité des données aujourd'hui mobilise des chercheurs de divers horizons; les bases de données, le web sémantique, l'analyse exploratoire de données, les techniques statistiques, la gestion des systèmes d'information, etc. Elle exige à la fois des recherches théoriques et des méthodes expérimentales. Les thèmes suivants seront portés par l'atelier, mais d'autres peuvent s'y ajouter :\n\n    Modèles pour la qualité des données\n        Définitions et vocabulaires\n        Cadres pour la définition des données et la qualification des données\n        Modèles, constructeurs et ontologies pour la qualité des données\n    Instruments pour l'évaluation de la qualité\n        Critères de qualité\n        Métriques d'évaluation de la qualité \n        Outils pour l'évaluation\n    Approches d'amélioration de la qualité\n        Méthodes de détection et de correction de la qualité \n        Méthodes d'exploration des données\n        Méthodes de prévention et/ou de correction de la qualité\n    Validation et expérimentation \n        Etudes de cas\n        Benchmarks\n\n\nDates importantes :\n\n    Date limite de soumission des articles : 04 décembre 2015 minuit\n    Notification aux auteurs : 18 décembre 2015\n    Version finale : 08 janvier 2015\n    Atelier : 19 janvier 2016\n\n\nInstructions aux auteurs\n\nLes auteurs sont invités à soumettre leur proposition au format PDF sur EasyChair à l'adresse suivante https://easychair.org/conferences/?conf=qlod2016\nLa taille des soumissions sera de 12 pages maximum. Elle pourra être beaucoup plus courte, en particulier pour les articles présentant un travail qui débute ou une présentation de projet de recherche.\n\nResponsables de l'atelier\n\n    Samira Si-said Cherfi (CEDRIC – Conservatoire National des Arts et Métiers)\n    Fayçal Hamdi (CEDRIC – Conservatoire National des Arts et Métiers)",
      "created_time": "2015-10-27T11:09:43+0000"
    },
    {
      "message": "ATELIER EGC- CLUCO\nClustering et Co-clustering\n\nAppel à Communication \nhttp://www.vincentlemaire-labs/CluCo2016\n\nAprès les éditions 2014 (30 participants à Rennes) et 2015 (35 participants au Luxembourg) et devant l’intérêt rencontré par les thématiques de recherche concernées nous proposons une nouvelle édition de l’atelier CluCo lié au clustering et Co-clustering.\n\nLa classification non supervisée ou clustering est en effet de nos jours largement utilisée dans un nombre croissant d’applications dans des domaines aussi divers que l’analyse d’image, la reconnaissance de formes , la fouille de textes, la gestion de la relation client, la veille scientifique ou technologique, la bioinformatique, la recherche d’information, l’analyse de réseaux sociaux…\n\nBien que le clustering forme un domaine de recherche en soi, avec une longue histoire, et d’innombrables méthodes, de nombreuses questions se posent toujours, telles que par exemple:\n\n• quel(s) sont les bons paramètre(s) : nombre de classes versus finesse d’analyse ?\n\n• comment estimer la qualité d’un clustering, l’importance des variables explicatives ?\n\n• les classes doivent-elles être strictes, floues, ou recouvrantes ?\n\n• comment rendre un clustering robuste et résistant au bruit ?\n\n• comment évaluer l’évolution temporelle du déploiement d’un clustering ?\n\n• …\n\n \nDe nombreuses questions ont été ouvertes lors de la table ronde ayant eu lieu lors de l’édition de l’atelier en 2015 (voir la fin des actes 2015), l’édition 2016 sera peut-être l’occasion répondre à certaines d’entre elles.\n \n\nFormat de l’atelier :\n\nL'objectif de cet atelier est de favoriser des présentations et des discussions. Peuvent être soumis :\n\n-              des résumés étendus* (4 pages)\n\n-              des articles longs* (maximum 12 pages)\n\n-              des propositions de démonstration logicielles* (4 pages)\n\n \n\nLes contributions seront publiées sous forme d’actes en ligne (avec ISBN). La soumission de prises de position bien articulées, d’expériences industrielles et de travaux en cours sont les bienvenus et privilégiés. Des contributions portant sur l'intérêt pratique des travaux, qu'elles viennent de l'industrie ou du monde académique, ou présentant des collaborations entre les deux seraient appréciées. Le but est le partage d’expérience et de savoir sur les problématiques liées au clustering (coclustering).\n\nPour les démonstrations : une présentation orale aménagée devra être préparée (temps de présentation plus court, et temps pour effectuer la démo sur projecteur en fin de présentation). Un temps sera aussi prévu dans le programme pour les démos.\n\n \n\nLe format à utiliser est le même que pour EGC\n\nLes soumissions sont à faire sur : https://easychair.org/conferences/?conf=cluco16\n\n \n\nPrincipaux thèmes de l'atelier (liste non exhaustive) :\n\n-              Clustering, Coclustering\n\n-              Clustering (coclustering) supervisé\n\n-              Clustering (coclustering) semi-supervisé\n\n-              Indice de qualité d’un clustering (coclustering)\n\n-              Mesure d’importance Locale au cluster des variables après la réalisation d’un clustering (coclustering)\n\n-              Mesure d’importance Globale aux clusters des variables après la réalisation d’un clustering (coclustering)\n\n-              Méthode automatique ou critère pour la détermination du bon nombre de clusters\n\n-              Algorithme de clustering (coclustering) pour grande volumétrie\n\n-              Méthode de mesure de l'évolution d’un clustering\n\n-              Clustering sous contraintes\n\n \n\nDates importantes (dates prévisionnelles) :\n\n-              Date limite de soumission des articles    05/12/2015\n\n-              Notification aux auteurs                                               22/12/2015\n\n-              Version finale                                                                    10/01/2016\n\n-              Atelier                                                                  19/01/2016\n\n \n\nComité d’organisation :\n\nVincent Lemaire                               Pascal Cuxac                       Jean-Charles Lamirel\n\nORANGE-LABS                                  INIST-CNRS                         SYNALP-LORIA",
      "created_time": "2015-10-21T13:39:15+0000"
    },
    {
      "message": "Bonjour,\n\nVoici le premier appel à communications pour l'atelier Fouille de Données Complexes (FDC) en conjonction avec EGC 2016 à Reims.\n\nToutes nos excuses en cas de réceptions multiples.\nMerci de diffuser cet appel à toute personne susceptible d'être intéressée.\n\nCordialement,\n\nPour les organisateurs de l'atelier,\nCamille Kurtz\n\nAtelier Fouille de Données Complexes (FDC@EGC2016) - 13ème édition\n\nAppel à communications\n\nAtelier organisé dans le cadre de la 16ème édition de la conférence\n\n« Extraction et Gestion des Connaissances » EGC 2016 (http://egc2016.univ-reims.fr)\n\nCet atelier est devenu au fil des années un lieu privilégié de rencontre où chercheurs/industriels viennent partager leurs expériences et expertises dans le domaine de la fouille de données complexes. L'atelier est ouvert en termes de propositions. Nous souhaitons stimuler particulièrement des discussions aussi bien du point de vue expérimental que théorique, académique et industriel. Les présentations pourront concerner aussi bien des travaux aboutis, des réflexions, que des études préliminaires (exposant davantage des problématiques originales que des solutions) en fouille de données complexes. Enfin, les discussions sur les problématiques inter ou pluridisciplinaires sont également bienvenues.\n\nSite Web de l'atelier : http://eric.univ-lyon2.fr/~gt-fdc/afdc16/\n\nSite de soumission : https://easychair.org/conferences/?conf=fdcegc2016\n\nContact : fdcegc2016@easychair.org (pour toute demande d'information complémentaire)\n\n\nDates importantes\nDate limite de soumission des résumés : 13 Novembre 2015\n\nDate limite de soumission des papiers : 20 Novembre 2015\n\nNotification aux auteurs : 8 Décembre 2015\n\nRéception des versions finales : 15 Décembre 2015\n\nProgramme préliminaire : 19 Décembre 2015\n\nDéroulement de l'atelier FDC : 19 Janvier 2016 à Reims\n\nInstructions aux auteurs\n\nLes auteurs sont invités à soumettre électroniquement leur proposition en utilisant easychair :\n\nhttps://www.easychair.org/conferences/?conf=fdcegc2016\n\nLa taille des soumissions sera de 12 pages maximum. Elle pourra être beaucoup plus courte, en particulier pour les articles présentant un travail qui débute ou présentation de projet de recherche. Le format latex à utiliser est celui de la revue « Revue des Nouvelles Technologie de l'Information » (RNTI) disponible à l'adresse suivante : http://www.editions-rnti.fr/files/RNTI-X-Y2.1.zip\n\nLa langue officielle de l'atelier sera le français, mais des articles en anglais pourront être acceptés.\n\n \nDéroulement de la journée :\n\nL'atelier sera constitué d'une série d'exposés, présentations orales suivies d'un temps de questions et de discussions, mais également des posters avec des démonstrations de résultats de recherche. Les articles soumis feront l'objet de rapports de lecture par au moins deux relecteurs afin d'améliorer leur qualité et conseiller les auteurs. Nous encourageons les présentations de jeunes chercheurs. Ceci peut permettre à un doctorant de présenter son projet de recherche. Cette partie de l'atelier est particulièrement importante pour les travaux qui débutent et pour la mise en place de groupes de recherche sur des thèmes partagés. Les présentations de posters pourront concerner des projets de recherche (européen, ANR, etc.) qui intéressent la communauté scientifique.\n\nDescription\n\nDans de nombreux domaines (multimédia, imagerie médicale, géomatique, web-sémantique, etc.), les données à traiter sont de plus en plus complexes et volumineuses.\n\nNous sommes ainsi conduits à manipuler des données souvent non structurées :\n\n    issues de diverses provenances comme des capteurs ou sources physiques d'informations variées ;\n    représentant la même information à des dates différentes ;\n    regroupant différents types d'informations (images, textes) ou encore de natures différentes (logs, contenu de documents, ontologies, etc.) ;\n    ayant des distributions différentes et déséquilibrées.\n    ...\n\nAussi la fouille de données complexes ne doit plus être considérée comme un processus isolé mais davantage comme une des étapes du processus plus général d'extraction de connaissances dans les bases de données, mais aussi dans les entrepôts de données. En effet, avant d'appliquer des techniques de fouille de données, les données complexes ont besoin de mise en forme et de structuration. La centralisation de données provenant de multiples sources de données dans un entrepôt de données soulève alors de nombreuses problématiques de recherche, alors même que cet entreposage peut assurer la qualité des données qui pourront par la suite faire l'objet d'une extraction de connaissances.\n\nDans ce contexte, la complexité peut concerner les processus (acquisition, structuration, entreposage, extraction de connaissances) ou les données elles-mêmes (données manquantes, floues, incertaines, ...).\n\nNous sollicitons des soumissions portant sur les thèmes suivants (liste non limitative) :\n\n    Pré-traitement, structuration et organisation des données complexes\n    Entrepôt/entreposage de données complexes\n    Processus et méthodes de fouille de données complexes\n    Classification et fusion de données multi-sources et distribuées\n\n    Clustering et segmentation de données non structurées\n    Fouille de données multimédia\n    Fouille de données imprécises et/ou incertaines\n\n    Les apports mutuels des méthodes de fouille de données et d'apprentissage et plus particulièrement les conditions qui justifient de faire appel aux unes et aux autres, les améliorations respectivement apportées\n    Rôle des connaissances en fouille de données complexes\n    Intégration de connaissances dans les processus de fouille de données complexes\n    Ontologie et fouille de données\n    Retours d'expériences d'extraction de connaissances à partir de données complexes dans des domaines spécifiques (bio-médical, commercial, usages du Web...)\n\n\nResponsables :\nCécile FAVRE (ERIC, Université Lumière Lyon 2)\nGermain FORESTIER (MIPS, Université de Haute Alsace)\nCamille KURTZ (LIPADE, Université Paris 5)",
      "created_time": "2015-10-14T13:24:44+0000"
    },
    {
      "message": "Bonjour,\n\nDésormais bien établi à EGC, l'atelier VIF émane du groupe de travail Visualisation d'Information, Interaction et Fouille de données, fruit de la collaboration entre les associations EGC et AFIHM.\n\nL'atelier se propose de faire le point sur l'actualité en visualisation interactive d'informations, tant du point de vue fondamental que des applications.\n\nIl aura pour vocation de favoriser l'échange sur l'évolution récente des axes de recherche dans ces thématiques, et sur l'application des méthodes de visualisation à des problématiques industrielles. Le traitement de données massives (Big Data) et des flux de données fera l'objet d'une attention particulière.\n\nPlus d'information sur le site web de l'atelier : http://gt-vif.polytech.univ-nantes.fr/egc-vif2016/index.php\n\nDates importantes : \n\n    5 décembre 2015 : Date limite de réception des propositions\n    16 décembre 2013 : Notification aux auteurs\n    19 décembre 2015 : Mise en ligne du programme\n    19 janvier 2016 : Atelier\n\nInstructions aux auteurs :\nLes soumissions se feront sous la forme de résumés de 2 pages maximum en suivant le format d'EGC (voir http://www.editions-rnti.fr/files/RNTI-X-Y2.1.zip), et doivent être soumis avant le 5 décembre 2015 (notification aux auteurs le 16 décembre 2015). Les résumés et les présentations collectées le jour de l'atelier seront de plus mis à disposition sur le Web.\n\nLes soumissions sont à faire via le site easychair à l'URL suivante https://easychair.org/conferences/?conf=ateliervifegc2016.\n\nComité d'organisation :\n\n    Hanene Azzag, LIPN, Université de Paris 13\n    Pierrick Bruneau, Luxembourg Institute of Science and Technology\n    Fabien Picarougne, LINA, Université de Nantes",
      "created_time": "2015-10-14T13:23:14+0000"
    },
    {
      "message": "EGC 2016 aura lieu à Reims : http://egc2016.univ-reims.fr/index.php/Pr%C3%A9sentation",
      "created_time": "2015-10-05T14:25:55+0000"
    }
  ]
}